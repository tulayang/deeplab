# 什么是 Qdrant？
# =================================
#
# Qdrant 是一个开源的向量相似度搜索引擎（Vector Similarity Search Engine），
# 专为高效处理高维向量数据而设计。它支持多种机器学习场景，如推荐系统、
# 图像/文本检索、语义搜索等。
#
# 1. 高效的向量搜索
#
# - 支持近似最近邻（ANN）搜索，优化大规模向量检索性能。
# - 内置多种索引算法（如 HNSW、IVF），平衡速度与准确性。
#
# 2. 灵活的存储与扩展
#
# - 提供内存（In-Memory）和磁盘（On-Disk）混合存储模式，适应不同资源需求。
# - 支持分布式部署，可横向扩展以处理十亿级向量规模。
#
# 3. 丰富的API与工具
#
# - 提供 RESTful API 和 gRPC 接口，方便集成到现有系统。
# - 官方 Python 客户端（qdrant-client）简化开发流程。
#
# 4. 多模态支持
#
# - 支持标量过滤（Filtering），允许结合向量相似度和结构化数据（如标签、时间范围）
#   进行混合搜索。
# 
# 5. 开源与云服务
#
# - 开源版本（GitHub）可自托管，适合定制化需求。
# - 提供托管云服务（Qdrant Cloud），免运维且支持自动扩缩容。
#
# 典型使用场景
# ----------------------------
# 
# - 推荐系统：根据用户行为向量快速匹配相似物品。
# - 语义搜索：将文本转换为向量（如 BERT、Sentence-BERT），实现语义级查询匹配。
# - 图像/视频检索：通过特征向量搜索相似视觉内容。
# - 异常检测：在向量空间中识别偏离正常模式的数据点。
#
# 对比其他向量数据库
# ----------------------------
#
# =========== ======== =========== ============= =================
# 特性	       Qdrant	 Milvus	     Pinecone	       FAISS
# =========== ======== =========== ============= =================
# 开源	       ✅	   ✅	        ❌（托管）	    ✅（库）
# 分布式支持	 ✅	   ✅	        ✅（云原生）	  ❌
# 混合搜索	   ✅  	 ✅	        ✅	            ❌
# 部署复杂度	 中等	   较高	        无需部署	     低（嵌入代码）
# 托管服务	   ✅  	 ❌	        ✅	            ❌
# =========== ======== =========== ============= =================
#
# 什么是 Embedding 模型？
# =================================
#
# Embedding 模型的本质是将非结构化数据（如文本、图片、音频）映射到向量空间，
# 使得语义/视觉相似的物体在向量空间中距离更近。
#
# 传统数据库处理的是结构化数据（如数字、字符串），通过精确匹配或范围查询
# （例如 WHERE price > 100）检索数据。向量数据库则专为处理非结构化数据
# （如文本、图片、音频）设计，通过 Embedding 模型将其转换为高维向量，并在
# 向量空间中搜索相似性。
#
# 向量数据库（如 Qdrant）的核心逻辑是与 Embedding 模型配合使用，两者共同
# 构成一个完整的“非结构化数据处理系统”。
#
# ========== ============================ ============== ===========================
# 数据形式	    Embedding 模型示例	       输出向量维度	      相似性定义
# ========== ============================ ============== ===========================
# 文本	      Sentence-BERT、OpenAI API	    384~1536 维	   语义相似（如“猫”≈“宠物”）
# 图片	      ResNet、CLIP	                512~2048 维	   视觉相似（如猫图≈狗图）
# 音频	      Wav2Vec、VGGish	               128~512 维	   声学特征相似
# ========== ============================ ============== ===========================
#
# 为什么需要 Embedding 模型？
# ----------------------------
# 
# 直接将原始数据（如图像像素、文本字符）存入数据库毫无意义，因为：
#
# - 维度灾难：一张 256x256 的图片有 65,536 维像素，无法直接计算相似性。
# - 语义丢失：像素或字符无法表达高层语义（如“照片中的情绪”）。
#
# Embedding 模型通过深度学习压缩信息，生成低维、稠密的向量，保留语义/视觉特征。
#
# 关键流程
# =================================
#
# 1. 转换：非结构化数据（如文本、图片、音频）→ Embedding 模型 → 向量
#          （例如：将一段文本转换为 384 维的浮点数数组）
# 2. 存储：向量 → 存入向量数据库
#          （附加元数据，如文本的原文、来源等）
# 3. 搜索：输入非结构化数据 → 转换为向量 → 从数据库找相似向量
#
#------------------------------------------------------------------------------
#
# 示例：构建一个 “法律条文检索系统”，允许用户用自然语言描述问题，找到相关法律条款。
#
#-------------------------------------------------------------------------------
# Sentence Transformers 是一个用于生成句子、段落或文本嵌入（embeddings）的软件库，
# 基于 Hugging Face 的 Transformers 库构建。它专门针对句子级别的表示进行优化，
# 能够将文本转换为高维向量，捕捉语义信息，适用于以下任务：
#
# - 语义相似度计算：通过向量相似度（如余弦相似度）衡量文本间的语义相关性。
# - 文本检索：在大规模文本库中快速找到与查询语句相关的文本。
# - 聚类与分类：将文本嵌入用于聚类（如K-means）或分类任务（如SVM）。
# - 多语言支持：提供预训练的多语言模型，支持跨语言文本处理。
#
# 特点：
#
# - 预训练模型：提供多种预训练模型（如all-MiniLM-L6-v2、
#               paraphrase-multilingual-MPNet-base-v2），适用于不同场景。
# - 微调支持：支持用自定义数据微调模型，适应特定任务。
# - 高效计算：优化句子嵌入生成，适合处理大规模数据。
#
# 常用模型：
# 
# - all-MiniLM-L6-v2：轻量级英文模型，平衡速度与性能。
# - paraphrase-multilingual-MPNet-base-v2：支持多语言的通用模型。
# - stsb-roberta-large：适用于语义相似度任务的高性能模型。
# - BAAI/bge-base-zh-v1.5：中文，通用场景，平衡速度与精度。
# - BAAI/bge-large-zh-v1.5：中文，高精度，适合复杂任务。
# - BAAI/bge-m3：多语言，跨语言检索，混合向量支持。
#
#--------------------------------------------------------------------------------
# 1. 生成向量（Embedding 模型）
#    
#    原始数据：法律条文文本（如《刑法》第 264 条：“盗窃公私财物，数额较大的...”）
#    使用模型：sentence-transformers/all-MiniLM-L6-v2（专为语义相似性优化的模型）
#
from sentence_transformers import SentenceTransformer

# 加载预训练模型 - 如本地没有，自动从网络下载
# 建议指定环境变量 HF_ENDPOINT=https://hf-mirror.com 使用国内镜像
model = SentenceTransformer('BAAI/bge-base-zh-v1.5')

# 1.1 模拟法律条文数据（真实场景需替换为实际数据）
law_texts = [
  "盗窃公私财物，数额较大的，处三年以下有期徒刑、拘役或者管制，并处或者单处罚金。",
  "故意伤害他人身体的，处三年以下有期徒刑、拘役或者管制。",
  "以暴力、胁迫或者其他方法抢劫公私财物的，处三年以上十年以下有期徒刑，并处罚金。",
  "明知是犯罪所得及其产生的收益而予以窝藏、转移、收购、代为销售或者以其他方法掩饰、隐瞒的，处三年以下有期徒刑、拘役或者管制，并处或者单处罚金。"
]
law_ids = [101, 102, 103, 104]  # 假设这是法律条文的唯一编号

# 1.2 生成向量 - 转换为 768 维向量（返回 numpy.ndarray）
vectors = model.encode(law_texts, convert_to_numpy=True) # 输出 shape: (N, 768)
print('------')
print(vectors)
print('------')

# 1.3 转换为 Qdrant 需要的格式：Python 列表的列表
vectors_list = vectors.tolist()  # shape: (4, 768) → [[0.1, 0.2, ...], ...]
print('------')
print(vectors_list)
print('------')

#--------------------------------------------------------------------------------
# 2. 存入向量数据库（Qdrant）
#    

from qdrant_client import QdrantClient

client = QdrantClient(
  url='http://127.0.0.1:16333',
  api_key='DifyAi!2025220'
)

# 2.1 创建集合
client.create_collection(
    collection_name="laws",
    vectors_config={
      "size": 768, 
      "distance": "Cosine" # 余弦相似度（可选：Cosine / Euclidean / Dot
    }
)

# 列出集合
collections = client.get_collections()
print(collections)

# 2.2 插入向量 - 构造 points 列表（ID + 向量 + Payload）
# client.upsert(
#     collection_name="my_collection",
#     points=[{"id": 1, "vector": [0.1, 0.2, ...], "payload": {"tag": "example"}}]
# )
points = []
for idx, (law_id, vector, text) in enumerate(zip(law_ids, vectors_list, law_texts)):
  points.append({
    "id": law_id,  # 唯一标识符（整数或字符串）
    "vector": vector,
    "payload": {
      "text": text,
      "article_id": law_id,
      "description": f"法律条文示例 {idx + 1}"
    }
  })
client.upsert(
    collection_name="laws",
    points=points
)
print("数据插入完成！插入数量:", len(points))

#--------------------------------------------------------------------------------
# 3. 执行相似性搜索 - 用户查询（自然语言描述）
#    

user_query = "偷东西会被判多久？"

query_vector = model.encode(user_query).tolist()  # 转换为列表

# 搜索最相似的 2 个条文
results = client.search(
    collection_name="laws",
    query_vector=query_vector,
    limit=2,
    with_payload=True  # 返回 payload 数据
)

# 打印结果
print("\n搜索查询:", user_query)
for rank, hit in enumerate(results, 1):
  print(f"\n=== 结果 #{rank} ===")
  print(f"法律条文 ID: {hit.id}")
  print(f"相似度得分: {hit.score:.4f}")  # 余弦相似度范围 [-1, 1]，越高越相似
  print(f"内容: {hit.payload['text']}")

  