# ä¸Šä¸‹æ–‡é•¿åº¦ï¼š64K     
# æœ€å¤§æ€ç»´é“¾é•¿åº¦ï¼š32K 
# æœ€å¤§è¾“å‡ºé•¿åº¦ï¼š8K    
#
# Temperatureï¼šé»˜è®¤ 1.0 -- å»ºè®®ï¼š
#
#   ä»£ç ç”Ÿæˆ/æ•°å­¦è§£é¢˜   - 0.0
#   æ•°æ®æŠ½å–/åˆ†æ       - 1.0
#   é€šç”¨å¯¹è¯            - 1.3
#   ç¿»è¯‘                - 1.3
#   åˆ›æ„ç±»å†™ä½œ/è¯—æ­Œåˆ›ä½œ - 1.5
#
# é™é€Ÿï¼š
#
#   - DeepSeek API ä¸é™åˆ¶ç”¨æˆ·å¹¶å‘é‡ï¼Œæˆ‘ä»¬ä¼šå°½åŠ›ä¿è¯æ‚¨æ‰€æœ‰è¯·æ±‚çš„æœåŠ¡è´¨é‡ã€‚

import os
from openai import OpenAI

# 1. åŸºæœ¬è°ƒç”¨
################################################## 
#
# curl http://<Host>:<Port>/v1/chat/completions \
#   -H "Content-Type: application/json" \
#   -H "Authorization: Bearer <API key>" \
#   -d '{
#         "model": "DeepSeek-R1",
#         "messages": [
#           {"role": "system", "content": "ä½ æ˜¯ä¸ªæ‡‚ç¼–ç¨‹çš„åŠ©ç†ã€‚"},
#           {"role": "user", "content": "ä½ æ˜¯è°!"}
#         ],
#         "stream": false
#       }'
#
# {
#   "id": "chatcmpl-5e4bfedcdb41453dabe2254cf934cdc6",
#   "object": "chat.completion",
#   "created": 1741597864,
#   "model": "DeepSeek-R1",
#   "choices": [
#     {
#       "index": 0,
#       "message": {
#         "role": "assistant",
#         "reasoning_content": null,
#         "content": "<think>\n...\n</think>\n\nä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼Œ...ğŸ˜Š",
#         "tool_calls": []
#       },
#       "logprobs": null,
#       "finish_reason": "stop",
#       "stop_reason": null
#     }
#   ],
#   "usage": {
#     "prompt_tokens": 12,
#     "total_tokens": 47,
#     "completion_tokens": 35,
#     "prompt_tokens_details": null
#   },
#   "prompt_logprobs": null
# }(base) 
#
##################################################

client = OpenAI(api_key="<API key>", base_url="http://<Host>:<Port>/v1")

response = client.chat.completions.create(
  model="DeepSeek-R1",
  messages=[
    {"role": "system", "content": "ä½ æ˜¯ä¸ªæ‡‚ç¼–ç¨‹çš„åŠ©ç†ã€‚"},
    {"role": "user", "content": "ä½ å¥½!"}
  ],
  stream=False
)

print(response)
print(response.choices[0].message.content)

# 2. åˆ—å‡ºæ¨¡å‹
################################################## 
# 
# curl -L -X GET 'http://<Host>:<Port>/v1/models' \
# -H 'Accept: application/json' \
# -H 'Authorization: Bearer deepseek-hello'
#
# {
#   "object": "list",
#   "data": [
#     {
#       "id": "DeepSeek-R1",
#       "object": "model",
#       "created": 1741598218,
#       "owned_by": "vllm",
#       "root": "/sdses02/zl/deepseek/DeepSeek-R1",
#       "parent": null,
#       "max_model_len": 16384,
#       "permission": [
#         {
#           "id": "modelperm-d72d2737da134743a2cae4988abc2b4e",
#           "object": "model_permission",
#           "created": 1741598218,
#           "allow_create_engine": false,
#           "allow_sampling": true,
#           "allow_logprobs": true,
#           "allow_search_indices": false,
#           "allow_view": true,
#           "allow_fine_tuning": false,
#           "organization": "*",
#           "group": null,
#           "is_blocking": false
#         }
#       ]
#     }
#   ]
# }(base)
#
##################################################

client = OpenAI(api_key="<API key>", base_url="http://<Host>:<Port>/v1")
print(client.models.list())